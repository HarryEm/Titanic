---
title: 'Titanic: Comparing Two Approaches for Missing Data'
author: "Harry Emeric"
date: "27 November, 2017"
output:
  html_document:
    number_sections: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: united
    highlight: tango
---

# Introduction

Here I build on my previous Kernel (please see link below) to compare two different approaches to dealing with missing data. The first approach is to impute missing data, for example making a prediction from the available variables. The second method is to train a separate model for each comination of missing fields we observe in the dataset. My aim is to see which approach has higher predictive accuracy. I made a start on this previously by doing this just for the "Age" variable, and found that it did not improve accuracy, although this could be due to lost information by binning "Age" into brackets. In this work I look to generalise this approach to all variables.

https://www.kaggle.com/harryem/feature-engineering-on-the-titanic-for-0-81339

## The problem

Given test features $X_{TEST} \in /R^{n * k}$ is a matrix of n test examples and k features and vector $y_{TEST} \in \{0,1\}^n$ classifying survived (1) or did not survive (0), our aim is to estimate a function f such that $y = f(x)$ which minimises misclassification, that is $$ min \sum_{i=1}^{n}(y_i - f(x_i))^2$$ where $f(x_i)$ is the prediction for the ith test example and $y_i$ is the ith classification, which is known only by the Kaggle administrators.

## Loading libraries and data

Loading libraries

```{r,message=FALSE}
library(ggplot2) #charting
library(scales) #charting
library(grid) #charting
library(plyr) #data wrangling
library(dplyr) #data wrangling
library(tidyr) #data wrangling
library(Hmisc) #data wrangling
library(mice) #imputing variables
library(randomForest) #modelling
library(caret) #modelling


traindata <- read.csv('../input/train.csv', stringsAsFactors = F)
testdata <- read.csv('../input/test.csv', stringsAsFactors = F)

c(object.size(traindata),object.size(testdata))

testdata$Survived <- "NA"
merged <- rbind(traindata,testdata)

length(unique(merged$PassengerId)) == length(merged$PassengerId) # check no duped entries
```

The data is small so performance shouldn't be an issue. 

I want to combine training and test sets because this makes it easier to perform the # same operations on both sets

# Initial Data Wrangling and Exploratory Data Analysis

For detailed impormation about features check here https://www.kaggle.com/c/titanic/data

```{r}
head(merged)
colSums(is.na(merged))
colSums(merged=="")
```

There is missing data in the Age, Fare, Cabin and Embarked varibles, and the aim of this piece is to explore and contrast various ways of approaching this issue.

We need to add a field classifying which data are missing for each element.

```{r}
a <- colSums(is.na(testdata))+colSums(testdata=="")
a <- names(a[is.na(a)|a!=0])
a

missing <- c()

for (i in a) {
  missing <- paste(missing,as.integer(!is.na(merged[i])^!merged[i]==""),sep="")
                 }

merged[missing=="100",] 

#There is only one example of this combination and its in the test set. I will discuss this later.

table(missing)
merged$Missing <- missing
```

0 means missing and 1 means observed, so for example "100" means Age was observed, Fare and Cabin were not.

There are five different combinations of missing variables in the data, so the approach will be train a separate model for each of these five possibilities


First let's review the charts of survivor trends by age, class, gender.

## Class & Sex

```{r}
merged$Pclass <- as.factor(merged$Pclass)
merged$Sex <- as.factor(merged$Sex)

g <- ggplot(merged[1:891,], aes(x=Pclass,fill=factor(Survived))) + geom_bar(pos  = "dodge") + labs(fill = "Survived",title="Survivor split by ticket class")

dftemp <- merged[1:891,] %>%
    group_by(Pclass) %>%
    summarise(Survive = sum(Survived == 1) / n(),
              DidNotSurvive = sum(Survived == 0) / n()) %>%
    gather(key = Group,value = Surv,Survive:DidNotSurvive)

gn <- ggplot(dftemp, aes(x = Pclass,
                            y = Surv, 
                            fill = as.factor(Group))) + 
    geom_bar(position = "dodge",stat = "identity") + 
    scale_y_continuous(labels = percent_format()) +
    labs(y = "Proportion Survived",title="Survivor split by ticket class - Normalized") +
    theme(legend.title=element_blank(), plot.title = element_text(size=14))


vp <- viewport(width = 0.3, height = 0.3, x = 0.85,
     y = 0.85)

print(gn)
theme_set(theme_bw(base_size = 8))
print(g,vp=vp)

g <- ggplot(merged[1:891,], aes(x=Pclass,fill=factor(Survived))) + geom_bar(pos  = "fill") + facet_wrap(~Sex) + labs(y = "Proportion Survived",fill = "Survived",title="Survivor split by ticket class and gender")
g + theme(plot.title = element_text(size=14))
```

As expected, higher class of ticket and female gender seem to be good positive predictors of survival.

## Age

I would like to segment by age and create a new feature for age bracket for visualisation, and to see if this improves model performance relative to using individual ages.

```{r}
qplot(merged$Age,fill=I("red"),xlab = "Age")

agebrackets <- c(0,13,18,30,55)
merged$Agebracket <- findInterval(merged$Age,agebrackets)

agetable <- data.frame(Agebracket=c(1,2,3,4,5),Age_range=c("<13","13-17","18-29","30-54","55+"))
merged <- join(merged,agetable,by="Agebracket")
merged$Agebracket <- as.factor(merged$Agebracket)

g <- ggplot(merged[1:891,], aes(x=Age_range,fill=factor(Survived))) + geom_bar(pos="dodge") + labs(fill = "Survived",title="Survivor split by age group") + theme(axis.text.x = element_text(angle = 90, hjust = 1))

dftemp <- merged[1:891,] %>%
    group_by(Age_range) %>%
    summarise(Survive = sum(Survived == 1) / n(),
              DidNotSurvive = sum(Survived == 0) / n()) %>%
    gather(key = Group,value = Surv,Survive:DidNotSurvive)

gn <- ggplot(dftemp, aes(x = Age_range,
                            y = Surv, 
                            fill = as.factor(Group))) + 
    geom_bar(position = "dodge",stat = "identity") + 
    scale_y_continuous(labels = percent_format()) +
    labs(y = "Proportion Survived",title="Survivor split by age group - Normalized") +
    theme(legend.title=element_blank(),plot.title = element_text(size=14))

vp <- viewport(width = 0.3, height = 0.3, x = 0.85,
     y = 0.85)

print(gn)
theme_set(theme_bw(base_size = 8))
print(g,vp=vp)

g <- ggplot(merged[1:891,], aes(x=Age_range,fill=factor(Survived))) + geom_bar(pos="fill") + labs(y = "Proportion Survived",fill = "Survived",title="Survivor split by age and gender - Normalized") + facet_wrap(~Sex)
g + theme(plot.title = element_text(size=14))
```

Age bracket seems to give a lot of information, with youger generally having a better chance
of survival. Interestingly elderly women has a very good chance of survival whereas elderly men
had a very bad chance so it looks like this is a useful division.


# Feature Engineering, Cleaning and Completing the Data

I now need to impute the missing data for that analysis, as I already have the pre imputation field "Missing" I can subset the data based on the what was originally missing. Each new feature is based off a single feature in the original data, so we can map that according to the "Missing" field.

The Cabin variable has many missing entries. I'm guessing this isn't just missing data, but that a lot of people didn't have a Cabin. So I shall turning this into a 2 factor variable, has / does not have cabin.

In my previous work I binned some of the variables together for fear of overfitting. However I saw little evidence of overfitting, for example that regularizing the logistic regression model provided very little improvement. As such I will avoid binning variables such as Age and Title, apart from for visualisation purposes.

## Cabin

```{r}
head(merged$Cabin,30)
length(unique(merged$Cabin))/length(merged$Cabin) ## only 14% are unique so there are a lot shared.
merged$Cabin[28] # this looks strange, multiple cabins on one ticket
subset(merged,Cabin == "C23 C25 C27") # it was one family, the Fortunes

merged$HasCabin <- as.factor(!(merged$Cabin==""))

g <- ggplot(merged[1:891,], aes(x=HasCabin,fill=factor(Survived))) + geom_bar()
g <- g +facet_wrap(~Pclass) + labs(title="Survivor split by class and Cabin") + theme(axis.text.x = element_text(angle = 90, hjust = 1))

gn <- ggplot(merged[1:891,], aes(x=HasCabin,fill=factor(Survived))) + geom_bar(pos="fill")
gn <- gn +facet_wrap(~Pclass) +labs(y = "Proportion Survived",fill = "Survived",title="Survivor split by class and Cabin - Normalized") + theme(plot.title = element_text(size=14))

vp <- viewport(width = 0.35, height = 0.35, x = 0.85,
     y = 0.8)

print(gn)
theme_set(theme_bw(base_size = 8))
print(g,vp=vp)

```

As expected few people in Class 2 and 3 had cabins, but actually those who did had a good chance of 
survival. Helping to capture the smaller number who survived from lower classes should be very additive.

## Fare

```{r}
qplot(merged$Fare,bins=150,fill=I("red"),xlab = "Fare")
```

There doesn't seem to be natural brackets here unlike age, so I will just
split in equal groups. There is one missing entry for Fare, I will impute
the average Fare for his Pclass.

```{r}
a <- subset(merged,is.na(merged$Fare))
a
merged[a[,1],]$Fare <- mean(subset(merged,Pclass==3)$Fare,na.rm=TRUE)

merged$Farebracket <- as.factor(cut2(merged$Fare,g=5))

g <- ggplot(merged[1:891,], aes(x=Farebracket,fill=factor(Survived))) + geom_bar(pos="fill")
g <- g +facet_wrap(~Pclass) + labs(y = "Proportion Survived",fill = "Survived",title="Survivor split by class and Fare Bracket - Normalized")
g <- g + theme(axis.text.x = element_text(angle = 90, hjust = 1),plot.title = element_text(size=14))
g 

subset(merged,Fare==0)
```

This is more useful than expected, it does seem to split out the survivors within
a class quite nicely. There were 17 people who paid 0 fare including some in first
class - I don't think its worth creating a separate category here though.

One group paid over $500.

```{r}
head(order(merged$Fare,decreasing = TRUE))
merged[259,]

subset(merged,Fare==merged$Fare[259])
```

```{r}
g <- ggplot(merged[1:891,],aes(x=Fare,y=Age,shape=factor(Survived),color=factor(Survived))) + geom_point() + scale_shape_manual(values=c(1,3)) + xlim(0, 300)

g <- g +facet_wrap(~Pclass) + labs(fill="Survived",title="Survival scatterplot of Fare and Age, Split by Class") + theme(plot.title = element_text(size=14))
g
```

This is a useful chart and shows some clustering of survivors in Class 2 who have low Age and Fare.

## Title


```{r}
merged$Title <- gsub('(.*, )|(\\..*)', '', merged$Name)

count(merged,Title)

merged$Title <- as.factor(merged$Title)

a <- count(merged,Title)

a <- a[a$n>2,]$Title
dftemp <- merged[1:891,]
dftemp <- dftemp[dftemp$Title %in% a,]

g <- ggplot(dftemp, aes(x=Title,fill=factor(Survived))) + geom_bar(pos="fill")
g <- g +facet_wrap(~Pclass) + labs(y = "Proportion Survived",fill = "Survived",title="Survivor split by class and Title - Normalized") + theme(plot.title = element_text(size=14))
g
```

This does appear to be useful on the normalized scale.

## Name

This added very little to my prior analysis so I will omit here.

## Ticketsize variable

Create a variable for number of people on a single tickt to give a count for group size.

```{r}
merged <- ddply(merged,.(Ticket),transform,Ticketsize=length(Ticket))
merged$Ticketsize <- as.factor(merged$Ticketsize)
merged <- merged[order(merged$PassengerId),] # ddply mixes up order
```

## Embarked

Move the two cases where this is unmarked to the modal case, "S"

```{r}
count(merged,Embarked)
subset(merged,Embarked == "")
merged[c(62,830),"Embarked"] <- "S"
merged$Embarked <- as.factor(merged$Embarked)
```

## Age

To begin with, I want to use the mice library to impute the missing ages. Then I want to check if we get improvement by splitting data as explained above. One issue with using other variables to impute missing data is that the variables used in that model are then double counted for those entries.

```{r}
m1 <- merged[, !names(merged) %in% c("Agebracket","Age_range")]
mice_ages <- mice(m1[, !names(m1) %in% c('PassengerId','Name','Ticket','Cabin','Family','Surname','Survived','Missing')], method='rf',seed = 1234)
mice_out <- mice::complete(mice_ages)

merged$Age <- mice_out$Age
merged$Agebracket <- findInterval(merged$Age,agebrackets)
merged <- join(merged,agetable,by="Agebracket")

colSums(is.na(merged))+colSums(merged=="")

```

# Model Fitting and Comparison

First split the data back into training/ CV and set we use for submission,

```{r}
mergedtrain <- merged[1:891,]
mergedtest <- merged[892:1309,]
mergedtrain$Survived <- as.factor(traindata$Survived)

set.seed(414)
inTrain<- createDataPartition(y=mergedtrain$Survived,p=0.75, list=FALSE)
train <- mergedtrain[inTrain,]
test <- mergedtrain[-inTrain,]
```

For each of these comparisons I will use random forest models as these were the best performing models in my prior analysis.

## Age Variable and the effect of Grouping

```{r}
set.seed(414)

rf_agegroups <- randomForest(factor(Survived) ~ Pclass + Sex + Farebracket + Agebracket + HasCabin + Ticketsize + Embarked + Title,
                       data = mergedtrain ,na.action = na.pass,nodesize=20)

rf_agegroups

rf_age <- randomForest(factor(Survived) ~ Pclass + Sex + Farebracket + Age + HasCabin + Ticketsize + Embarked + Title,
                       data = mergedtrain ,na.action = na.pass,nodesize=20)

rf_age
rf_age$confusion
varImpPlot(rf_age)
importance(rf_age)
```

It appears that grouping ages has a negative effect on performance, but only slightly.

## Generalised Model fit based on which variables are missing.

This approach references Goodfellow et al. "Deep Learning", information can be found on page 98 under the section entitled "Classification with missing inputs".

http://www.deeplearningbook.org/contents/ml.html

For each combination of missing variables, contained in the "Missing" field, I train a random forest model, and then predict on the test set using the model relevant to each test example's "Missing"" combination.

```{r}

unique(merged$Missing)

dftemp <- mergedtrain[,c("Survived","Pclass","Sex","Fare","Age","HasCabin","Ticketsize","Embarked","Title","Missing")]

rf110 <- randomForest(factor(Survived) ~ .,
                        data = subset(dftemp[,!names(dftemp) %in% c("HasCabin")],dftemp$Missing=="110"))

rf111 <- randomForest(factor(Survived) ~ .,
                        data = subset(dftemp[,!names(dftemp) %in% c()],dftemp$Missing=="111"))

rf010 <- randomForest(factor(Survived) ~ .,
                        data = subset(dftemp[,!names(dftemp) %in% c("Age","HasCabin")],dftemp$Missing=="010"))

rf011 <- randomForest(factor(Survived) ~ .,
                        data = subset(dftemp[,!names(dftemp) %in% c("Age")],dftemp$Missing=="011"))

rf100 <- rf111

rf110$confusion
rf111$confusion
rf010$confusion
rf011$confusion
```

There are no training examples for the Missing = 100 example in the test set; as its one example I will just use the imputed value for HasCabin and Fare and treat it the same as the Missing = 111 model.

# Evaluation and submission

I predict each test example depending on which combination of variables were observed.

```{r}
p110 <- predict(rf110,mergedtest[mergedtest$Missing=="110",])
p111 <- predict(rf110,mergedtest[mergedtest$Missing=="111",])
p010 <- predict(rf110,mergedtest[mergedtest$Missing=="010",])
p011 <- predict(rf110,mergedtest[mergedtest$Missing=="011",])
p100 <- predict(rf110,mergedtest[mergedtest$Missing=="100",])
```

# Evaluation and submission

Finally, I prepare the submission file to send to Kaggle.

```{r}
submission <- rbind(data.frame(PassengerId=names(p110),Survived=p110),data.frame(PassengerId=names(p111),Survived=p111),data.frame(PassengerId=names(p010),Survived=p010),data.frame(PassengerId=names(p011),Survived=p011),data.frame(PassengerId=names(p100),Survived=p100))

if(!file.exists("./predictions.csv")) {
        write.csv(submission, file = "./predictions.csv",row.names = F)}
```

This submission obtained 0.79425 accuracy, which is a decent amount worse than the 0.81339 I obtained from imputing variables and running a single random forest model. Lookined at some of the individual confusion matrices for the models, I expect this is because the training data isn't large enough to split into so many partitions. I would be interested to see how this approach performs on a larger dataset.